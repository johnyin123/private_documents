# cat >> config/pipelines.yml <<EOF
# - pipeline.id: nginxlog
#   pipeline.workers: 2
#   pipeline.batch.size: 125
#   pipeline.batch.delay: 50
#   path.config: "/etc/logstash/conf.d/nginx_pipeline.conf"
# EOF
input {
  udp {
    port => 5140
    host => "0.0.0.0"
    type => "syslog"
    tags => ["ngx_access", "ngx_error"]
  }
}
filter {
  if [type] == "syslog" {
    grok {
      match => { "message" => "<%{POSINT:syslog_pri}>%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{PROG:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
      add_tag => [ "syslog_parsed_ok" ]
    }
    json {
      source => "syslog_message"
      target => "parsed_json_data" # Store parsed JSON in a new field
      tag_on_failure => ["json_parsed_error"]
      skip_on_invalid_json => true
      remove_field => [ "syslog_message" ] # Remove original message if desired
    }
  }
}
output {
  # elasticsearch {
  #   hosts => ["localhost:9200"]
  #   index => "nginx-%{+YYYY.MM.dd}"
  # }
  stdout { codec => rubydebug }
}
