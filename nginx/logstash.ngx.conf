# cat >> config/pipelines.yml <<EOF
# - pipeline.id: nginxlog
#   pipeline.workers: 2
#   pipeline.batch.size: 125
#   pipeline.batch.delay: 50
#   path.config: "/etc/logstash/conf.d/nginx_pipeline.conf"
# EOF
input {
  udp {
    port => 5140
    host => "0.0.0.0"
    type => "syslog"
    tags => ["ngx_access", "ngx_error"]
  }
}
filter {
  if [type] == "syslog" {
    if "ngx_access" in [tags] {
      grok {
        match => { "message" => "<%{POSINT:syslog_pri}>%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{PROG:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
        add_tag => [ "syslog_parsed_ok" ]
      }
      json {
        source => "syslog_message"
        target => "parsed_json_data" # Store parsed JSON in a new field
        tag_on_failure => ["json_parsed_error"]
        skip_on_invalid_json => true
        remove_field => [ "message","syslog_message","event" ]
      }
      date {
        match => [ "[parsed_json_data][time_iso8601]", "ISO8601" ]
        target => "@timestamp"
        remove_field => [ "time_iso8601" ]
      }
      if [http_x_forwarded_for] {
        geoip {
          source => "http_x_forwarded_for"
          target => "geoip"
        }
      } else if [remote_addr] {
        geoip {
          source => "remote_addr"
          target => "geoip"
        }
      }
    }
  }
}
output {
  # elasticsearch {
  #   hosts => ["localhost:9200"]
  #   index => "nginx-%{+YYYY.MM.dd}"
  # }
  stdout { codec => rubydebug }
}
